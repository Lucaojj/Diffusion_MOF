{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95de778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi,cos,sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f2ec1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi,cos,sin\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from queue import PriorityQueue\n",
    "os.chdir('/home/lucasperea/GraphMaterials')\n",
    "# diffusion_df = pd.read_excel('../Downloads/MOF_Diffusion_CH4.xlsx')\n",
    "# diffusion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ec42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433595ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77eeda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aab67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ed80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba13d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeda62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b24ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0c6bbe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mat_pr_dic' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store mat_pr_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669eafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8516e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "234cff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "# mat_dic = {}\n",
    "\n",
    "pool = multiprocessing.Pool(3)\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "volumen_res = pool.map_async(Diffusion, os.listdir('./Nt2Files_MOF')[:3])\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()\n",
    "\n",
    "# Parallel(n_jobs=num_cores)(delayed(Diffusion(file,mat_dic)) for file in os.listdir('./Nt2Files_MOF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dic = {}\n",
    "Diffusion('KEGZOL02_clean.nt2', trial_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e04d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548de4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eefdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/lucasperea/Documents/Diffusion_MOF/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_nodes = len(final.nodes)\n",
    "for node_pr in final.nodes:\n",
    "    final.nodes[node_pr]['pagerank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f4b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONVAT_neutral_b.nt2\n",
      "SOXDEQ_clean.nt2\n",
      "JOGHIY_clean.nt2\n",
      "RASGAT_clean.nt2\n",
      "SOMFAC_clean.nt2\n",
      "OZAVUI_clean.nt2\n",
      "UTADIE_clean.nt2\n",
      "VILXOE_clean.nt2\n",
      "DUNXUH04_clean.nt2\n",
      "RESSAK_clean.nt2\n",
      "OKITAE_clean.nt2\n",
      "TOPKIT_clean.nt2\n",
      "UBIPAY_clean.nt2\n",
      "RONWIA_clean.nt2\n",
      "ZIDBEV_clean.nt2\n",
      "COWMAD_clean.nt2\n",
      "ZEZPUR_clean.nt2\n",
      "AFOVIB_clean.nt2\n",
      "SADLIU_clean.nt2\n",
      "EFIMOV_clean.nt2\n",
      "UREVOE_clean.nt2\n",
      "RANPAA_clean.nt2\n",
      "PIYZED_clean.nt2\n",
      "VASFED_clean.nt2\n",
      "ZEXKUK_clean.nt2\n",
      "USUWUC_clean.nt2\n",
      "RULQIY_clean.nt2\n",
      "DUNXUH03_clean.nt2\n",
      "SUNJER_clean.nt2\n",
      "ANONAT_manual.nt2\n",
      "QOMDUS_clean.nt2\n",
      "KEDJAG02_clean.nt2\n",
      "VACFUB_clean_h.nt2\n",
      "TILVOZ_clean.nt2\n",
      "UCOCUM_neutral.nt2\n",
      "RAWZIA_clean.nt2\n",
      "SETSIV_clean.nt2\n",
      "JOFKIA_clean.nt2\n",
      "PIZPET_clean_h.nt2\n",
      "IKETOH_manual.nt2\n",
      "PAVMAB_clean.nt2\n",
      "KIBDIJ_clean.nt2\n",
      "WUZQOZ_clean.nt2\n",
      "ARAFOP_clean.nt2\n",
      "VIRKIQ_clean.nt2\n",
      "DAPBIH_neutral.nt2\n",
      "KOSLUB_clean.nt2\n",
      "XAMDUM04_clean.nt2\n",
      "GOGWAB_clean.nt2\n",
      "ABULOB_clean.nt2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mat_dic = {}\n",
    "# def Diffusion(file):\n",
    "for file in os.listdir('./Nt2Files_MOF/'):\n",
    "    \n",
    "#     start_time = time.time()\n",
    "\n",
    "    \n",
    "#     mat_dic = {}\n",
    "    \n",
    "    nt2_name = file\n",
    "\n",
    "    vector_pos, vector_ort, pos_order, twentysix_faces_neigh, vector_values_latt = CellLocation(nt2_name)\n",
    "    G, connection_cell, larger_node_dic = GraphCell(nt2_name, pos_order)\n",
    "    final, key_plus = GraphMultiCell(G, vector_pos, vector_ort, pos_order, connection_cell, twentysix_faces_neigh)\n",
    "    neigh_dic, flow_coef = PageRankParameter(final)\n",
    "\n",
    "    def unit_sum(pagerank_list):\n",
    "        return pagerank_list/sum(pagerank_list)\n",
    "\n",
    "    # Loop over the number of iterations we want to run pagerank\n",
    "    def pagerank(graph, iteration, flow_coef, neigh_dic):\n",
    "        node_list = sorted(list(graph.nodes))\n",
    "        for i in range(iteration):\n",
    "            pagerank_list = pagerank_one_iter(graph, flow_coef, neigh_dic, node_list)\n",
    "        return pagerank_list\n",
    "\n",
    "    # Loop over the nodes of the graph\n",
    "    def pagerank_one_iter(graph, flow_coef, neigh_dic, node_list):\n",
    "#         pagerank_values = {}\n",
    "        for selfnode in node_list:\n",
    "            update_pagerank(selfnode, flow_coef, neigh_dic, graph)\n",
    "#             pagerank_values[selfnode] = pr_value\n",
    "#         for key in pagerank_values:\n",
    "#             graph.nodes[key]['pagerank'] = pagerank_values[key]\n",
    "        pagerank_list = np.asarray([graph.nodes[node]['pagerank'] for node in node_list], dtype='float32')\n",
    "        return pagerank_list\n",
    "\n",
    "    # Update of the nodes attribute pagerank following the rule we describe in connections\n",
    "    def update_pagerank(selfnode, flow_coef, neigh_dic, graph):\n",
    "        in_neighbors = neigh_dic[str(selfnode)] #self.parents\n",
    "        pagerank_sum = sum(graph.nodes[node]['pagerank']*flow_coef[str(selfnode)][str(node)]\n",
    "                           for node in in_neighbors)\n",
    "       \n",
    "        graph.nodes[selfnode]['pagerank'] = pagerank_sum\n",
    "#         return pagerank_sum\n",
    "    \n",
    "    \n",
    "#     with open('./DataPageRank/FlowCoef/FlowCoef_' + file, 'wb') as handle:\n",
    "#         pickle.dump(flow_coef, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#     with open('./DataPageRank/MaterialGraph/MaterialGraph_' + file, 'wb') as handle:\n",
    "#         pickle.dump(final, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#     with open('./DataPageRank/NeighData/NeighData_' + file, 'wb') as handle:\n",
    "#         pickle.dump(neigh_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    info = pagerank(final, 50, flow_coef, neigh_dic)\n",
    "\n",
    "\n",
    "    #     print(list(G.nodes)[-1] + 1, names_nodes_center_cell[-1])\n",
    "    names_nodes_center_cell = list(np.array(G.nodes) + key_plus*pos_order['000'])\n",
    "\n",
    "    pgrk_nodes = []\n",
    "\n",
    "    for node in names_nodes_center_cell:\n",
    "        pgrk_nodes.append((node, final.nodes[node]['pagerank']))\n",
    "\n",
    "    last = 0\n",
    "    for node, pgrk in pgrk_nodes:\n",
    "\n",
    "        if pgrk > last:\n",
    "            max_pr = (node, pgrk)\n",
    "            last = pgrk\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    most_connected_node_cell = max_pr[0]-pos_order['000']*key_plus\n",
    "    most_connected_node_cell_value = max_pr[1]\n",
    "\n",
    "\n",
    "    letter_name = nt2_name.split('.')[0]\n",
    "    radius_nodes = []\n",
    "    for node in final.nodes:\n",
    "        radius_nodes.append(final.nodes[node]['rad_max_sph'])\n",
    "        \n",
    "    mat_dic[letter_name] = {'MostConnectedNodeCell':most_connected_node_cell, \n",
    "                            'RadiusMCNC':final.nodes[most_connected_node_cell]['rad_max_sph'],\n",
    "                            'MostConnectedNodeCellValue':most_connected_node_cell_value,\n",
    "                           'RadiusLargerNode':max(radius_nodes)}\n",
    "\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(file)\n",
    "#     return mat_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store mat_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ede3dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a05da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d00be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045c6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CellLocation(nt2_name):\n",
    "    \n",
    "    from pymatgen.core.structure import Structure\n",
    "    from math import pi, cos, sin\n",
    "    \n",
    "    six_letter_code = nt2_name.split('.')[0]\n",
    "    \n",
    "    path_nt2_file = './Nt2Files_MOF/' + nt2_name\n",
    "    path_cif_file = './MOF/' + six_letter_code + '.cif'\n",
    "    \n",
    "    cif_structure = Structure.from_file(path_cif_file)\n",
    "    \n",
    "    latt = cif_structure.lattice\n",
    "    \n",
    "    # Angles of the cell's axis\n",
    "    alpha = latt.alpha\n",
    "    beta = latt.beta\n",
    "    gamma = latt.gamma\n",
    "\n",
    "    # Constant to change from degrees to radians\n",
    "    cte = pi/180\n",
    "\n",
    "    # Vectors proyections of the cell's vector over the ortogonal axis\n",
    "    x_axis = latt.a\n",
    "    y_axis = latt.b\n",
    "    z_axis = latt.c\n",
    "\n",
    "    # Cell's vectors\n",
    "    a, b, c = round(x_axis*sin(beta*cte), 3) , 0 ,round(x_axis*cos(beta*cte), 3)\n",
    "    d, e, g = round(y_axis*cos(gamma*cte), 3) ,round(y_axis*sin(gamma*cte), 3), 0\n",
    "    l, m, n = 0, round(z_axis*cos(alpha*cte), 3), round(z_axis*sin(alpha*cte), 3)\n",
    "    \n",
    "    vector_values_latt = (a, b, c, d, e, g, l, m, n)\n",
    "\n",
    "    # Constant that limits the maximum number of cells that could expand over every direction \n",
    "    # (axis and diagonal direction)\n",
    "    r = 1\n",
    "\n",
    "    cubic_comb = []\n",
    "    \n",
    "    # Each of the cell's vectors represent the length of the cell in that direction.\n",
    "    # Independently of which length it is if you multiply the length of one of the vector by two it is clear\n",
    "    # that the result vector will give the information about the location of the second cell in the direction\n",
    "    # of the vector we multiply by two.\n",
    "\n",
    "    # We generate the location of the cells for a cube of length equals to len(range(-r, r + 1))\n",
    "    # r = 1, len(range(-r, r + 1)) = 27\n",
    "    # The information of location of the cells are saved in real coordinates using the combination of the \n",
    "    # cell's vectors and in an orthogonal base transformation using as vectors the numbers (i,j,k) we use to multiply \n",
    "    # the cell's vectors\n",
    "    for i in range(-r, r+1):\n",
    "        for j in range(-r, r+1):\n",
    "            for k in range(-r, r+1):\n",
    "                cubic_comb.append((np.array([a,b,c])*i + np.array([d,e,g])*j + np.array([l,m,n])*k,\n",
    "                                   np.array([i,j,k])))\n",
    "\n",
    "    vector_pos = []\n",
    "    vector_ort = []\n",
    "    # Unpack values\n",
    "    # We also choose as a center the vector 0 \n",
    "    \n",
    "    #     print('This is the Lattice vector: {}'.format(lattice_vector.abc))\n",
    "\n",
    "    for vec, ort in cubic_comb:\n",
    "        vector_pos.append(list(vec))\n",
    "        vector_ort.append(list(ort))\n",
    "\n",
    "    # Later in this Notebook we are going to create a graph for every vector we generated in the previous step.\n",
    "    # These graphs will be composed by nodes whose names will be an ordered number.\n",
    "    # The names will be assigned by the order the graphs were generated.\n",
    "    # That means every graph will have as the name of their nodes a range of numbers whose length will be equal \n",
    "    # to the name of the last node we create in the first graph.\n",
    "    # In order to keep track of the order we create we are going to establish that order by numbered the orthogonal\n",
    "    # vectors\n",
    "\n",
    "    pos_order = {}\n",
    "    i = 0\n",
    "    for vector in vector_ort:\n",
    "        name = str(vector[0]) + str(vector[1]) + str(vector[2]) \n",
    "        pos_order[name] = i\n",
    "        i += 1\n",
    "\n",
    "    twentysix_faces_neigh = [np.array(vector_name) for vector_name in vector_ort]\n",
    "    \n",
    "    return vector_pos, vector_ort, pos_order, twentysix_faces_neigh, vector_values_latt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3e41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dce5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphCell(nt2_name, pos_order):\n",
    "    \n",
    "    import networkx as nx\n",
    "    \n",
    "    # Initialize a networkx's graph. \n",
    "    # We take the information about the nodes and edges from the .nt2 file and passes it out to the graph.\n",
    "\n",
    "    # Every node in the graph will have three attributes.\n",
    "    # -Cartesian coordinate\n",
    "    # -Pagerank coefficient\n",
    "    # -Radius of the maximus sphere that fit in that node\n",
    "\n",
    "    # Evey edge will have one attribute:\n",
    "    # -Radius of the maximus sphere that can travel through the edge\n",
    "\n",
    "    # We are not going to save the information about edges that connect point from outside of the cell\n",
    "    \n",
    "    path_nt2_file = './Nt2Files_MOF/' + nt2_name\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    cell_names = list(pos_order.keys())\n",
    "    \n",
    "    connection_cell = {cell_name:[] for cell_name in cell_names}\n",
    "    \n",
    "    larger_dist_atom = []\n",
    "    \n",
    "    pagerank_init_value = 20\n",
    "    with open(path_nt2_file) as f:\n",
    "        line = ' '\n",
    "\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "\n",
    "            if line == 'Vertex table:\\n': \n",
    "\n",
    "                while line:\n",
    "\n",
    "                    line = f.readline()\n",
    "\n",
    "                    if line == '\\n':\n",
    "                        break\n",
    "                    else:\n",
    "                        line_list = line.split()\n",
    "                        key = int(line_list[0])\n",
    "                        coord_x = float(line_list[1])\n",
    "                        coord_y = float(line_list[2])\n",
    "                        coord_z = float(line_list[3])\n",
    "                        min_dist_atom = float(line_list[4])\n",
    "\n",
    "                        G.add_node(key, coord=np.array([coord_x, coord_y, coord_z]), rad_max_sph=min_dist_atom,\n",
    "                                  pagerank=pagerank_init_value)\n",
    "                        larger_dist_atom.append(min_dist_atom)\n",
    "\n",
    "            if line == 'Edge table:\\n':\n",
    "\n",
    "\n",
    "                while line:\n",
    "\n",
    "                    line = f.readline()\n",
    "                    if line == '':\n",
    "                        break\n",
    "                    line_list = line.split()\n",
    "                    \n",
    "                    origin = int(line_list[0])\n",
    "                    destination = int(line_list[2])\n",
    "                    \n",
    "                    larger_radius = float(line_list[3])\n",
    "                    \n",
    "                    x_sim = int(line_list[4])\n",
    "                    y_sim = int(line_list[5])\n",
    "                    z_sim = int(line_list[6])\n",
    "                    \n",
    "                    identifier = str(x_sim) + str(y_sim) + str(z_sim)\n",
    "                    \n",
    "                    if sum([abs(x_sim), abs(y_sim), abs(z_sim)]) == 0:\n",
    "                        G.add_edge(origin, destination, rad_max_sph=larger_radius)\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "                        connection_cell[identifier].append((origin,destination,larger_radius))\n",
    "\n",
    "    \n",
    "    larger_node = max(larger_dist_atom)\n",
    "    index_larger_node = np.argmax(larger_dist_atom)\n",
    "    name_larger_node = list(G.nodes)[index_larger_node]\n",
    "    \n",
    "    return G, connection_cell, {'LargerNode':larger_node, 'NameLargerNode':name_larger_node} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb6f746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.chdir('/home/lucasperea/GraphMaterials')\n",
    "\n",
    "# for nt2_name in os.listdir('./Nt2Files_MOF/'):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a121e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphMultiCell(G, vector_pos, vector_ort, pos_order, connection_cell, twentysix_faces_neigh):\n",
    "    \n",
    "    import networkx as nx\n",
    "    from copy import deepcopy\n",
    "    from networkx.relabel import relabel_nodes\n",
    "    # Create a dictionary which contains one graph for every cell we want to use to calculate the \n",
    "    # pagerank coefficients. \n",
    "    # These new graphs are a copy of the one that we initialized in previous step so, we \n",
    "    # change the names and the cartesian coordinates for every node\n",
    "\n",
    "    graph_mod= {}\n",
    "\n",
    "    # As we mentioned earlier we are goint to name the nodes wit a number.\n",
    "    # The name of the last node of the first graph plus one (because we start in 0) will give as the range in every \n",
    "    # graph.\n",
    "\n",
    "    key_plus = sorted(list(G.nodes), reverse=True)[0] + 1\n",
    "\n",
    "    # The names used as keys in the dictionary of graph are the ortogonal base transformations we calculated before\n",
    "    # They names are very useful to know the position of the graph with respect to the origin (0,0,0).\n",
    "\n",
    "    for i in range(len(vector_pos)):\n",
    "        name = str(vector_ort[i][0])+str(vector_ort[i][1])+str(vector_ort[i][2])\n",
    "        graph_mod[name] = deepcopy(G)\n",
    "\n",
    "        mapping_name = {}\n",
    "        multiplier = pos_order[name]\n",
    "        for node in graph_mod[name].nodes:\n",
    "            graph_mod[name].nodes[node]['coord'] += vector_pos[i] #*box\n",
    "            mapping_name[node] = node + key_plus*multiplier\n",
    "        relabel_nodes(graph_mod[name], mapping=mapping_name, copy=False)\n",
    "\n",
    "    # As you can see here it is really to see where the graph is if we now their name\n",
    "    #     print('Keys of the Dictionary of Graph: {}'.format(graph_mod.keys()))\n",
    "\n",
    "\n",
    "    # List with the names of the graph\n",
    "    \n",
    "    def symm(array):\n",
    "    \n",
    "        import numpy as np\n",
    "        first = np.where(array == 2, -1, array)\n",
    "        second = np.where(first == -2, 1, first)\n",
    "\n",
    "        return second \n",
    "\n",
    "    # Now we add to the graph the edges that connect with nodes outside of the cell. We do this for every graph \n",
    "    # in the dictionary\n",
    "\n",
    "    for j in range(len(vector_pos)):\n",
    "        for neighbor in twentysix_faces_neigh:\n",
    "            str_neighbor = str(neighbor[0]) + str(neighbor[1]) + str(neighbor[2]) \n",
    "\n",
    "            neig_loc = vector_ort[j] + neighbor\n",
    "            str_neig_loc = str(neig_loc[0])+str(neig_loc[1])+str(neig_loc[2])\n",
    "\n",
    "            if str_neig_loc in list(pos_order.keys()):\n",
    "                name = str(vector_ort[j][0])+str(vector_ort[j][1])+str(vector_ort[j][2])\n",
    "                multiplier_origin = pos_order[name]\n",
    "                multiplier_destination = pos_order[str_neig_loc]\n",
    "\n",
    "                for edge in connection_cell[str_neighbor]:\n",
    "                    edge_1 = edge[0] + multiplier_origin*key_plus\n",
    "                    edge_2 = edge[1] + multiplier_destination*key_plus\n",
    "                    rad_max_sph = edge[2]\n",
    "                    graph_mod[name].add_edge(edge_1, edge_2)\n",
    "                    graph_mod[name].edges[edge_1, edge_2]['rad_max_sph'] = rad_max_sph\n",
    "\n",
    "            else:\n",
    "                symm_vec = symm(neig_loc)\n",
    "\n",
    "                name = str(vector_ort[j][0])+str(vector_ort[j][1])+str(vector_ort[j][2])\n",
    "                str_neig_loc_symm = str(symm_vec[0])+str(symm_vec[1])+str(symm_vec[2])\n",
    "\n",
    "                multiplier_origin = pos_order[name]\n",
    "                multiplier_destination = pos_order[str_neig_loc_symm]\n",
    "\n",
    "                for edge in connection_cell[str_neighbor]:\n",
    "                    edge_1 = edge[0] + multiplier_origin*key_plus\n",
    "                    edge_2 = edge[1] + multiplier_destination*key_plus\n",
    "                    rad_max_sph = edge[2]\n",
    "                    graph_mod[name].add_edge(edge_1, edge_2)\n",
    "                    graph_mod[name].edges[edge_1, edge_2]['rad_max_sph'] = rad_max_sph\n",
    "\n",
    "    final = nx.Graph()\n",
    "\n",
    "    for key in graph_mod:\n",
    "        final.add_nodes_from(graph_mod[key])\n",
    "        final.add_edges_from(graph_mod[key].edges)\n",
    "        for node in graph_mod[key].nodes:\n",
    "            for attr in graph_mod[key].nodes[node]:\n",
    "                final.nodes[node][attr] = graph_mod[key].nodes[node][attr]\n",
    "\n",
    "        for edge in graph_mod[key].edges:\n",
    "            for attr in graph_mod[key].edges[edge[0], edge[1]]:\n",
    "                final.edges[edge][attr] = graph_mod[key].edges[edge][attr]\n",
    "                \n",
    "    return final, key_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06cc430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageRankParameter(final):\n",
    "\n",
    "    # We calculate the neighbors for every node in the graph\n",
    "    neigh_dic = {}\n",
    "    for n, nbrs in final.adj.items():\n",
    "        neigh = []\n",
    "        for nbr, eattr in nbrs.items():\n",
    "            neigh.append(nbr)\n",
    "\n",
    "\n",
    "        neigh_dic[str(n)] = neigh\n",
    "\n",
    "\n",
    "    # For every node we calculate the sum of the square radius of their edges\n",
    "    sum_radius = {}\n",
    "    for node in final.nodes:\n",
    "\n",
    "        sum_edges = 0\n",
    "        for nei in neigh_dic[str(node)]:\n",
    "\n",
    "            score = final[node][nei]['rad_max_sph']\n",
    "            sum_edges += score**2\n",
    "        sum_radius[str(node)] = sum_edges\n",
    "\n",
    "    #  conexion is a dictionary that saves information of the weights that every edge has in \n",
    "    # relationship with the total number of edges in the node.\n",
    "    # Every edge has a radius as attribute so we are using the proportion of the square of the radius divide by\n",
    "    # the sum of the square radius in the node\n",
    "\n",
    "    flow_coef = {}\n",
    "    \n",
    "    for node in final.nodes:\n",
    "\n",
    "        sub = {}\n",
    "        for nei in neigh_dic[str(node)]:\n",
    "            radius_node = final[node][nei]['rad_max_sph']\n",
    "            all_radius = sum_radius[str(nei)] \n",
    "            sub[str(nei)] = radius_node**2/all_radius\n",
    "        flow_coef[str(node)] = sub\n",
    "    return neigh_dic, flow_coef "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4cf2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "050c826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def TransfMatrix(vector_values_latt):\n",
    "\n",
    "    a,b,c,d,e,g,l,m,n = vector_values_latt\n",
    "    # Matrix to change the orthogonal base vector to the base vector of the unit cell\n",
    "\n",
    "    A = np.array([[a,b,c],[d,e,g], [l,m,n]]).transpose()\n",
    "    B1 = np.array([1, 0, 0])\n",
    "    B2 = np.array([0, 1, 0])\n",
    "    B3 = np.array([0, 0, 1])\n",
    "    X = np.array([np.linalg.inv(A).dot(B1),np.linalg.inv(A).dot(B2),np.linalg.inv(A).dot(B3)])\n",
    "    Y = X.transpose()\n",
    "\n",
    "    # Matrix to change the base vector of the unit cell for the orthogonal base vector\n",
    "    A1 = np.array([[1,0,0], [0,1,0], [0,0,1]]).transpose()\n",
    "    B4 = np.array([a,b,c])#*3\n",
    "    B5 = np.array([d,e,g])#*3\n",
    "    B6 = np.array([l,m,n])#*3\n",
    "    X1 = np.array([np.linalg.inv(A1).dot(B4),np.linalg.inv(A1).dot(B5),np.linalg.inv(A1).dot(B6)])\n",
    "    Y1 = X1.transpose()\n",
    "\n",
    "    return Y, Y1\n",
    "\n",
    "def distance(final, multi_box, Y, Y1):\n",
    "    # Function for the calculation of distances between axes\n",
    "    dim = 3\n",
    "    real_box = np.array([multi_box,multi_box,multi_box])\n",
    "    \n",
    "    for edge in final.edges:\n",
    "        p1 = Y.dot(final.nodes[edge[0]]['coord'])\n",
    "        p2 = Y.dot(final.nodes[edge[1]]['coord'])\n",
    "    #     print(p1, p2)\n",
    "        dist_3d = np.zeros((dim))\n",
    "        for j in range(dim):\n",
    "            dist = abs(p2[j]-p1[j])\n",
    "            if dist > real_box[j] * 0.5:\n",
    "                dist = abs(real_box[j] - dist)\n",
    "            dist_3d[j] = dist\n",
    "        \n",
    "        final[edge[0]][edge[1]]['distance'] = np.sqrt(np.sum(np.power(Y1.dot(dist_3d), 2)))\n",
    "    return final\n",
    "\n",
    "# for edge in final.edges:\n",
    "#     final[edge[0]][edge[1]]['distance'] = distance(final, edge[0], edge[1], 3, Y, Y1)\n",
    "\n",
    "\n",
    "\n",
    "def dijkstra(start_vertex, target, parents, final):\n",
    "\n",
    "    # Dictionary with keys = vertices and values = weights of the vertices (set as infinity at the start)\n",
    "    D = {}\n",
    "    visited = []\n",
    "    node_list = list(final.nodes)\n",
    "\n",
    "    D = {v:float('inf') for v in node_list}\n",
    "    D[start_vertex] = 0\n",
    "\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((0, start_vertex))\n",
    "\n",
    "    while not pq.empty():\n",
    "        (dist, current_vertex) = pq.get()\n",
    "        if current_vertex == target:\n",
    "            print('Target vertex: ' + str(target) + ' reached')\n",
    "            break\n",
    "        else:\n",
    "\n",
    "            visited.append(current_vertex)\n",
    "\n",
    "\n",
    "            # Loop for every vertex of the net\n",
    "            for neighbor in neigh_dic[str(current_vertex)]:\n",
    "#                         if self.edges[current_vertex][neighbor] != -1:\n",
    "               \n",
    "                distance_edge = final[current_vertex][neighbor]['distance']\n",
    "\n",
    "                if neighbor not in visited:\n",
    "                    old_cost = D[neighbor]\n",
    "                    new_cost = D[current_vertex] + distance_edge\n",
    "                    if new_cost < old_cost:\n",
    "                        pq.put((new_cost, neighbor))\n",
    "                        D[neighbor] = new_cost\n",
    "                        parents[neighbor] = current_vertex\n",
    "\n",
    "    return D, parents\n",
    "\n",
    "def backpedal(start_vertex, target, searchResult):\n",
    "\n",
    "    node = target\n",
    "\n",
    "    backpath = [node]\n",
    "\n",
    "    path = []\n",
    "\n",
    "    while node != start_vertex:\n",
    "\n",
    "        backpath.append(searchResult[node])\n",
    "\n",
    "        node = searchResult[node]\n",
    "\n",
    "    for i in range(len(backpath)):\n",
    "\n",
    "        path.append(backpath[-i - 1])\n",
    "\n",
    "    return path \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669a5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b05fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739853e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
